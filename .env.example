# GitHub Configuration
GITHUB_TOKEN=ghp_your_github_token_here
GITHUB_REPOSITORY=owner/repo-name

# LLM Provider (openai or yandex)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TIMEOUT=120

# Custom OpenAI-compatible API (optional)
# Uncomment and set for Azure, Ollama, vLLM, LocalAI, OpenRouter, etc.
# OPENAI_BASE_URL=http://localhost:11434/v1        # Ollama
# OPENAI_BASE_URL=http://localhost:8000/v1         # vLLM / LocalAI
# OPENAI_BASE_URL=https://openrouter.ai/api/v1     # OpenRouter
# OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment  # Azure

# YandexGPT Configuration (optional)
YANDEX_API_KEY=
YANDEX_FOLDER_ID=
YANDEX_MODEL=yandexgpt-lite

# Agent Configuration
MAX_ITERATIONS=5
LOG_LEVEL=INFO

# Workspace (for local development)
WORKSPACE_DIR=./workspace

# Langfuse Configuration (optional - for LLM observability)
# Get keys from your Langfuse project settings
# If not set, tracing is disabled (app works normally without it)
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
# For self-hosted Langfuse, set your instance URL:
LANGFUSE_BASE_URL=http://localhost:3000
